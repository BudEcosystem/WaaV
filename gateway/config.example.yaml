# WaaV Gateway Configuration File Example
#
# This file demonstrates all available configuration options.
# Copy this file to config.yaml and customize as needed.
#
# Usage: waav-gateway -c config.yaml
#
# Priority: YAML values > Environment variables > .env file > Defaults
# This means YAML configuration takes precedence over environment variables,
# allowing you to use env vars as base config and YAML for overrides.

# Server configuration
server:
  host: "0.0.0.0"      # ENV: HOST
  port: 3001           # ENV: PORT

  # TLS configuration (optional)
  # Enable for HTTPS/WSS support
  # Both cert_path and key_path must be provided when enabled
  tls:
    enabled: false                    # ENV: TLS_ENABLED (true/false/1/0/yes/no)
    cert_path: "/path/to/cert.pem"    # ENV: TLS_CERT_PATH (PEM format)
    key_path: "/path/to/key.pem"      # ENV: TLS_KEY_PATH (PEM format)

# LiveKit configuration
livekit:
  url: "ws://localhost:7880"              # ENV: LIVEKIT_URL
  public_url: "http://localhost:7880"     # ENV: LIVEKIT_PUBLIC_URL
  api_key: "your-livekit-api-key"         # ENV: LIVEKIT_API_KEY
  api_secret: "your-livekit-api-secret"   # ENV: LIVEKIT_API_SECRET

# Provider API keys
providers:
  deepgram_api_key: "your-deepgram-api-key"     # ENV: DEEPGRAM_API_KEY
  elevenlabs_api_key: "your-elevenlabs-api-key" # ENV: ELEVENLABS_API_KEY

  # Google Cloud settings (used for both Speech-to-Text and Text-to-Speech)
  # Authentication options (in order of precedence):
  # 1. Path to service account JSON file
  # 2. JSON content string (starts with '{')
  # 3. Empty string to use Application Default Credentials (ADC)
  # Note: project_id is automatically extracted from the credentials JSON
  google_credentials: ""                         # ENV: GOOGLE_APPLICATION_CREDENTIALS

  # Microsoft Azure Speech Services settings (used for both STT and TTS)
  # Get these from Azure Portal → Your Speech resource → Keys and Endpoint
  # IMPORTANT: The subscription key is tied to a specific Azure region.
  # Using a key with the wrong region will result in 401 Unauthorized errors.
  azure_speech_subscription_key: ""              # ENV: AZURE_SPEECH_SUBSCRIPTION_KEY
  # Azure region where your Speech resource was created
  # Common regions: eastus, westus, westus2, westeurope, northeurope, eastasia, southeastasia
  # Note: Both STT and TTS use the same region setting
  azure_speech_region: "eastus"                  # ENV: AZURE_SPEECH_REGION (default: eastus)

  # Cartesia API key (used for both STT and TTS)
  # STT uses ink-whisper model, TTS uses sonic-3 model
  # Get from Cartesia dashboard: https://play.cartesia.ai/
  cartesia_api_key: ""                           # ENV: CARTESIA_API_KEY

  # OpenAI API key (used for STT, TTS, and Realtime Audio-to-Audio)
  # STT: Whisper models (whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe)
  # TTS: TTS models (tts-1, tts-1-hd, gpt-4o-mini-tts)
  # Realtime: Full-duplex audio-to-audio (gpt-4o-realtime-preview)
  # Get from OpenAI dashboard: https://platform.openai.com/api-keys
  openai_api_key: ""                             # ENV: OPENAI_API_KEY

  # AssemblyAI API key (used for STT)
  # Streaming API v3 with real-time transcription
  # Get from AssemblyAI dashboard: https://www.assemblyai.com/app
  assemblyai_api_key: ""                         # ENV: ASSEMBLYAI_API_KEY

  # Hume AI API key (used for TTS and Realtime Audio-to-Audio)
  # TTS: Octave with natural language emotion control and voice cloning
  # Realtime: EVI (Empathic Voice Interface) with 48-dimension emotion analysis
  # Get from Hume dashboard: https://beta.hume.ai/
  hume_api_key: ""                               # ENV: HUME_API_KEY

  # LMNT API key (used for TTS and voice cloning)
  # TTS: Ultra-low latency (~150ms) text-to-speech with 22+ languages
  # Voice Cloning: Create custom voices from 5+ second audio samples
  # Supports HTTP streaming and WebSocket for real-time synthesis
  # Get from LMNT dashboard: https://app.lmnt.com/
  lmnt_api_key: ""                               # ENV: LMNT_API_KEY

  # Play.ht API credentials (used for TTS and voice cloning)
  # TTS: HTTP streaming with ~190ms latency, 36+ languages, PlayDialog multi-turn
  # Voice Cloning: Create custom voices from 30+ second audio samples
  # Voice engines: Play3.0-mini (fastest), PlayDialog (expressive), PlayHT2.0-turbo (legacy)
  # Get from Play.ht dashboard: https://play.ht/studio/api-access
  playht_api_key: ""                             # ENV: PLAYHT_API_KEY
  playht_user_id: ""                             # ENV: PLAYHT_USER_ID (required for dual-header auth)

  # AWS credentials for Amazon Transcribe (STT) and Amazon Polly (TTS)
  # Uses AWS SDK credential chain:
  # 1. These explicit credentials (if provided)
  # 2. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
  # 3. AWS credentials file (~/.aws/credentials)
  # 4. IAM role (when running on EC2/ECS/Lambda)
  # Get from AWS IAM console or use IAM roles for production
  aws_access_key_id: ""                          # ENV: AWS_ACCESS_KEY_ID
  aws_secret_access_key: ""                      # ENV: AWS_SECRET_ACCESS_KEY
  aws_region: "us-east-1"                        # ENV: AWS_REGION (default: us-east-1)

# STT Provider Configuration (optional - can also be set via WebSocket config)
# stt:
#   provider: deepgram  # Options: "deepgram", "google", "elevenlabs", "microsoft-azure", "cartesia", "openai", "assemblyai", "aws-transcribe"
#   # Google-specific settings (only used when provider is "google")
#   google:
#     location: global           # Options: global, us, eu, asia-southeast1, etc.
#     recognizer_id: ""          # Optional: pre-configured recognizer ID
#     model: latest_long         # Options: latest_long, latest_short, chirp_2, telephony
#   # AssemblyAI-specific settings (only used when provider is "assemblyai")
#   assemblyai:
#     speech_model: best        # Options: best, nano
#     region: us                # Options: us, eu
#     end_of_turn_confidence: 0.8  # Threshold for turn detection (0.0-1.0)
#     sample_rate: 16000        # Options: 8000, 16000 (recommended)
#   # AWS Transcribe-specific settings (only used when provider is "aws-transcribe")
#   aws_transcribe:
#     language: en-US           # Options: en-US, en-GB, es-US, fr-FR, de-DE, ja-JP, etc. (100+ languages)
#     media_encoding: pcm       # Options: pcm, ogg-opus, flac
#     sample_rate: 16000        # Options: 8000, 16000, 32000, 48000
#     enable_partial_results: true      # Receive interim transcripts
#     show_speaker_labels: false        # Enable speaker diarization
#     vocabulary_filter_method: remove  # Options: remove, mask, tag (for profanity filtering)

# TTS Provider Configuration (optional - can also be set via WebSocket config)
# tts:
#   provider: elevenlabs  # Options: "deepgram", "elevenlabs", "google", "azure", "cartesia", "openai", "aws-polly", "hume", "lmnt", "playht"
#   # Cartesia-specific settings (only used when provider is "cartesia")
#   cartesia:
#     model: sonic-3           # Options: sonic-3, sonic-3-2025-10-27
#     voice_id: ""             # Voice UUID from Cartesia voice library
#     audio_format: linear16   # Options: linear16/pcm, wav, mp3
#     sample_rate: 24000       # Options: 8000, 16000, 22050, 24000, 44100, 48000
#   # AWS Polly-specific settings (only used when provider is "aws-polly")
#   aws_polly:
#     voice: Joanna            # Options: Joanna, Matthew, Amy, Emma, Brian, Nicole, etc. (60+ voices)
#     engine: neural           # Options: standard, neural, long-form, generative
#     output_format: pcm       # Options: pcm, mp3, ogg_vorbis
#     sample_rate: 16000       # PCM: 8000, 16000 | MP3/OGG: 8000, 16000, 22050, 24000
#     text_type: text          # Options: text, ssml
#   # LMNT-specific settings (only used when provider is "lmnt")
#   lmnt:
#     voice: lily              # Options: lily, daniel, or custom voice IDs
#     model: blizzard          # Options: blizzard (current default model)
#     language: auto           # Options: auto, en, es, fr, de, it, pt, ja, ko, zh, etc. (22+ languages)
#     audio_format: linear16   # Options: linear16/pcm, mp3, ulaw, webm
#     sample_rate: 24000       # Options: 8000, 16000, 24000
#     top_p: 0.8               # Speech stability (0.0-1.0, lower = more stable)
#     temperature: 1.0         # Expressiveness (≥0, higher = more varied)
#     speed: 1.0               # Speech speed (0.25-2.0)
#
#   # Play.ht-specific settings (only used when provider is "playht")
#   # Requires PLAYHT_API_KEY and PLAYHT_USER_ID environment variables
#   playht:
#     voice: s3://voice-cloning-zero-shot/.../manifest.json  # Voice manifest URL
#     voice_engine: Play3.0-mini   # Options: Play3.0-mini (~190ms), PlayDialog (~350ms), PlayDialogMultilingual, PlayDialogArabic, PlayHT2.0-turbo
#     audio_format: mp3            # Options: mp3, wav, mulaw, flac, ogg, raw (PCM)
#     sample_rate: 48000           # Options: 8000, 16000, 24000, 44100, 48000
#     speed: 1.0                   # Speech speed (0.5-2.0)
#     temperature: 0.5             # Randomness (0.0-1.0)
#     language: en                 # ISO 639-1 language code (for Play3.0-mini only)
#     # Advanced guidance parameters (Play3.0, PlayHT2.0 only):
#     # text_guidance: 1.0         # Text adherence strength
#     # voice_guidance: 1.0        # Voice adherence strength
#     # style_guidance: 1.0        # Style adherence (Play3.0 only)
#     # PlayDialog multi-turn parameters (optional):
#     # voice_2: s3://...          # Second speaker voice URL
#     # turn_prefix: "S1:"         # First speaker identifier
#     # turn_prefix_2: "S2:"       # Second speaker identifier

# LiveKit recording configuration (S3)
recording:
  s3_bucket: "my-recordings"              # ENV: RECORDING_S3_BUCKET
  s3_region: "us-west-2"                  # ENV: RECORDING_S3_REGION
  s3_prefix: "recordings/production"      # ENV: RECORDING_S3_PREFIX
  s3_endpoint: "https://s3.amazonaws.com" # ENV: RECORDING_S3_ENDPOINT
  s3_access_key: "your-access-key"        # ENV: RECORDING_S3_ACCESS_KEY
  s3_secret_key: "your-secret-key"        # ENV: RECORDING_S3_SECRET_KEY

# Cache configuration
cache:
  path: "/var/cache/waav-gateway"  # ENV: CACHE_PATH (if omitted, uses in-memory cache)
  ttl_seconds: 2592000      # ENV: CACHE_TTL_SECONDS (default: 30 days)

# Authentication configuration
auth:
  required: false                             # ENV: AUTH_REQUIRED (true/false/1/0/yes/no)
  service_url: "https://auth.example.com"     # ENV: AUTH_SERVICE_URL
  signing_key_path: "/path/to/key.pem"        # ENV: AUTH_SIGNING_KEY_PATH
  # ENV: AUTH_API_SECRETS_JSON (JSON array of {id, secret})
  api_secrets:
    - id: "default"
      secret: "sk_test_default_123456"        # ENV: AUTH_API_SECRETS_JSON (preferred)
    - id: "partner-1"
      secret: "sk_test_partner_abcdef"        # ENV: AUTH_API_SECRETS_JSON (preferred)
  # Legacy single-secret alias (ignored when api_secrets is non-empty):
  # api_secret: "sk_test_legacy_123456"       # ENV: AUTH_API_SECRET (AUTH_API_SECRET_ID optional)
  timeout_seconds: 5                          # ENV: AUTH_TIMEOUT_SECONDS

# SIP configuration (optional)
# Used for SIP trunk integration and webhook forwarding
sip:
  room_prefix: "sip-"                         # ENV: SIP_ROOM_PREFIX
  # Naming prefix for SIP trunk and dispatch resources in LiveKit (defaults to "waav")
  # Format: {naming_prefix}-{room_prefix}-trunk and {naming_prefix}-{room_prefix}-dispatch
  naming_prefix: "waav"                       # ENV: SIP_NAMING_PREFIX
  allowed_addresses:                          # ENV: SIP_ALLOWED_ADDRESSES (comma-separated)
    - "192.168.1.0/24"
    - "10.0.0.1"

  # REQUIRED if hooks are configured: Global signing secret for webhook authentication
  # All outbound SIP webhooks are signed with HMAC-SHA256 for security
  # Generate with: openssl rand -hex 32
  # See docs/livekit_webhook.md#webhook-signing for details
  hook_secret: "your-global-signing-secret"   # ENV: SIP_HOOK_SECRET (min 16 chars, 32+ recommended)

  # Downstream webhook endpoints for SIP event forwarding
  # Each hook receives participant_joined events for matching SIP domains
  # All requests include X-WaaV Gateway-Signature header for verification
  #
  # Runtime management: Hooks can be added/replaced at runtime via the
  # POST /sip/hooks REST endpoint. Runtime changes are persisted to
  # <cache_path>/sip_hooks.json and merged with this config on startup.
  # Note: Runtime hooks use the global hook_secret (per-hook secrets not supported via API)
  hooks:                                      # ENV: SIP_HOOKS_JSON (JSON array with optional "secret" field)
    - host: "example.com"                     # SIP domain to match (case-insensitive)
      url: "https://webhook.example.com/events"  # HTTPS strongly recommended
      # Optional: per-hook secret override (omit to use global hook_secret)
      # Use for multi-tenant deployments or zero-trust architectures

    - host: "another.com"
      url: "https://webhook2.example.com/events"
